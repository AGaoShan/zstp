import json
import os
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Tuple, List, Any
import asyncio

from data_processing.vulnerability_entity_alignment import  align_and_ingest_entity
from input.md import chunk_md_with_headers
from llm.invoker import extract_audit_insights


def process_single_report(file_path: str, output_dir: str) -> Tuple[str, str]:
    """
    å¤„ç†å•ä¸ªå®¡è®¡æŠ¥å‘Šæ–‡ä»¶ï¼Œå¹¶åœ¨åŒæ­¥çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°ã€‚
    """
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        extracted_knowledge: List[Dict[str, Any]] = []

        # --- 1. å¼‚æ­¥åˆ†å—å’Œæå–é€»è¾‘ ---

        # å®šä¹‰ä¸€ä¸ªå†…éƒ¨çš„å¼‚æ­¥å‡½æ•°æ¥å°è£…å¼‚æ­¥è°ƒç”¨é“¾
        async def run_async_tasks():
            chunks: List[str] = []

            if file_ext == '.md':
                # ä¼ å…¥æ–‡ä»¶è·¯å¾„ç»™å¼‚æ­¥åˆ†å—å‡½æ•°ï¼Œå®ƒåœ¨å†…éƒ¨å¤„ç†è¯»å–å’Œåˆ†å—
                # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯ await chunk_md_with_headers(file_path)
                chunks = await chunk_md_with_headers(file_path,headers_to_split_on= [("##", "Header 2")])

            elif file_ext == '.txt':
                # å¯¹äº txt æ–‡ä»¶ï¼Œä»éœ€è‡ªå·±åŒæ­¥è¯»å–å†…å®¹ï¼Œç„¶åä½œä¸ºå•ä¸ªå—å¤„ç†
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    chunks = [content]
                except IOError as e:
                    # å¦‚æœtxtæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œç«‹å³æŠ›å‡ºé”™è¯¯
                    raise IOError(f"Failed to read TXT file: {e}")

            else:
                return []  # ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè™½ç„¶åœ¨å¤–å±‚å·²è¿‡æ»¤

            insights = []
            for chunk in chunks:
                # è°ƒç”¨ LLM æå–æ´å¯Ÿï¼ˆå‡è®¾ extract_audit_insights ä¹Ÿæ˜¯ async defï¼‰
                insight = extract_audit_insights(chunk)
                if insight:
                    insights.append(insight)
            return insights

        # åœ¨å½“å‰åŒæ­¥çº¿ç¨‹ä¸­ï¼Œå¯åŠ¨ä¸€ä¸ªä¸´æ—¶çš„äº‹ä»¶å¾ªç¯æ¥è¿è¡Œæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        # è¿™å°±æ˜¯å°†å¼‚æ­¥ä»£ç å®‰å…¨åœ°è¿è¡Œåœ¨ ThreadPoolExecutor çº¿ç¨‹ä¸­çš„å…³é”®
        extracted_knowledge = asyncio.run(run_async_tasks())

        # --- 2. ç»“æœä¿å­˜ (ä¿æŒåŒæ­¥) ---
        file_name = os.path.basename(file_path)
        output_file = os.path.join(output_dir, f"{os.path.splitext(file_name)[0]}_result.json")

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(extracted_knowledge, f, ensure_ascii=False, indent=2)

        print(f"âœ… æˆåŠŸå¤„ç†: {file_path}. æå–äº† {len(extracted_knowledge)} æ¡æ´å¯Ÿã€‚")
        return file_path, "success"

    except Exception as e:
        # æ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸ï¼ŒåŒ…æ‹¬ç”± asyncio.run å†…éƒ¨æŠ›å‡ºçš„å¼‚å¸¸
        error_msg = f"error: {type(e).__name__}: {str(e)}"
        traceback.print_exc()
        print(f"âŒ å¤„ç†å¤±è´¥: {file_path}, é”™è¯¯: {error_msg}")
        return file_path, error_msg



def batch_process_audit_reports(input_dir: str, output_dir: str, max_workers: int = 4) -> Dict[str, str]:
    """
    æ‰¹é‡å¹¶è¡Œå¤„ç†å®¡è®¡æŠ¥å‘Š
    """
    # ... (ä»£ç ä¸æ‚¨æä¾›çš„å®Œå…¨ä¸€è‡´) ...
    os.makedirs(output_dir, exist_ok=True)

    # è·å–æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶ï¼Œç°åœ¨æ”¯æŒ .txt å’Œ .md
    report_files = []
    for file in os.listdir(input_dir):
        # æ³¨æ„: å¦‚æœæ–‡ä»¶è·¯å¾„æ˜¯ç›¸å¯¹çš„ (å¦‚æ‚¨ç¤ºä¾‹ä¸­çš„ "../audit_reports")ï¼Œ
        # ç¡®ä¿ file æ˜¯å®Œæ•´è·¯å¾„ï¼Œå¦åˆ™å†…éƒ¨çš„ open/chunk_md_with_headers å¯èƒ½ä¼šå¤±è´¥ã€‚
        # æ‚¨çš„ä»£ç ä¸­ä½¿ç”¨äº† os.path.join(input_dir, file)ï¼Œè¿™æ˜¯æ­£ç¡®çš„åšæ³•ã€‚
        if file.endswith(('.txt', '.md')):
            report_files.append(os.path.join(input_dir, file))

    if not report_files:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å®¡è®¡æŠ¥å‘Šæ–‡ä»¶")
        return {}

    # å¹¶è¡Œå¤„ç†æ–‡ä»¶
    results = {}
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_file = {
            executor.submit(process_single_report, file, output_dir): file
            for file in report_files
        }

        # è·å–ç»“æœ
        for future in as_completed(future_to_file):
            file_path, status = future.result()
            results[file_path] = status

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    summary = {
        "total": len(results),
        "success": sum(1 for v in results.values() if v == "success"),
        "failed": sum(1 for v in results.values() if v.startswith("error:"))
    }

    # ä¿å­˜æ±‡æ€»ç»“æœ
    try:
        with open(os.path.join(output_dir, "summary.json"), 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ ä¿å­˜æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")

    print(f"\nğŸ“Š å¤„ç†å®Œæˆ: æ€»è®¡ {summary['total']} ä¸ªæ–‡ä»¶, æˆåŠŸ {summary['success']} ä¸ª, å¤±è´¥ {summary['failed']} ä¸ª")
    return results


def process_single_vulnerability_alignment(json_file_path: str) -> Tuple[str, Dict[str, Any]]:
    """
    å¤„ç†å•ä¸ª JSON æ–‡ä»¶ä¸­çš„æ¼æ´ç±»å‹å¯¹é½

    Args:
        json_file_path: JSON æ–‡ä»¶è·¯å¾„

    Returns:
        Tuple[æ–‡ä»¶è·¯å¾„, å¯¹é½ç»“æœå­—å…¸]
        å¯¹é½ç»“æœåŒ…å«:
        - status: "success" æˆ– "error"
        - aligned_vulnerabilities: å¯¹é½æˆåŠŸçš„æ¼æ´åˆ—è¡¨
        - failed_vulnerabilities: å¯¹é½å¤±è´¥çš„æ¼æ´åˆ—è¡¨
        - total_count: æ€»æ•°
        - success_count: æˆåŠŸæ•°
        - error_message: é”™è¯¯ä¿¡æ¯ (å¦‚æœæœ‰)
    """
    result = {
        "status": "error",
        "aligned_vulnerabilities": [],
        "failed_vulnerabilities": [],
        "total_count": 0,
        "success_count": 0,
        "error_message": None
    }

    try:
        # è¯»å– JSON æ–‡ä»¶
        with open(json_file_path, 'r', encoding='utf-8') as f:
            vulnerabilities = json.load(f)

        if not isinstance(vulnerabilities, list):
            result["error_message"] = "JSON æ–‡ä»¶æ ¼å¼é”™è¯¯: åº”è¯¥æ˜¯åˆ—è¡¨"
            return json_file_path, result

        result["total_count"] = len(vulnerabilities)

        # å¤„ç†æ¯ä¸ªæ¼æ´
        for idx, vuln_data in enumerate(vulnerabilities):
            try:
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                if 'vulnerability_type' not in vuln_data:
                    result["failed_vulnerabilities"].append({
                        "index": idx,
                        "error": "ç¼ºå°‘ vulnerability_type å­—æ®µ",
                        "original_data": vuln_data
                    })
                    continue

                # æ‰§è¡Œå®ä½“å¯¹é½
                alignment_result = align_and_ingest_entity(vuln_data)

                # è®°å½•å¯¹é½æˆåŠŸçš„æ¼æ´
                result["aligned_vulnerabilities"].append({
                    "index": idx,
                    "original_name": alignment_result['original_name'],
                    "aligned_name": alignment_result['aligned_entity_name'],
                    "action": alignment_result['action'],
                    "similarity": alignment_result.get('similarity'),
                    "entity_id": alignment_result.get('entity_id')
                })
                result["success_count"] += 1

                print(
                    f"  [{idx + 1}/{result['total_count']}] âœ“ {alignment_result['original_name']} -> {alignment_result['aligned_entity_name']}")

            except Exception as e:
                # è®°å½•å¯¹é½å¤±è´¥çš„æ¼æ´
                error_msg = f"{type(e).__name__}: {str(e)}"
                result["failed_vulnerabilities"].append({
                    "index": idx,
                    "error": error_msg,
                    "original_data": vuln_data
                })
                print(f"  [{idx + 1}/{result['total_count']}] âœ— å¯¹é½å¤±è´¥: {error_msg}")

        # å¦‚æœæœ‰æˆåŠŸçš„å¯¹é½ï¼Œåˆ™æ•´ä½“çŠ¶æ€ä¸ºæˆåŠŸ
        if result["success_count"] > 0:
            result["status"] = "success"

        print(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {json_file_path} - æˆåŠŸ {result['success_count']}/{result['total_count']}")
        return json_file_path, result

    except Exception as e:
        result["error_message"] = f"{type(e).__name__}: {str(e)}"
        traceback.print_exc()
        print(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {json_file_path} - {result['error_message']}")
        return json_file_path, result


def batch_process_vulnerability_alignment(output_dir: str, max_workers: int = 4) -> Dict[str, Any]:
    """
    æ‰¹é‡å¹¶è¡Œå¤„ç†è¾“å‡ºç›®å½•ä¸­çš„ JSON æ–‡ä»¶ï¼Œæ‰§è¡Œæ¼æ´ç±»å‹å¯¹é½

    Args:
        output_dir: åŒ…å« JSON ç»“æœæ–‡ä»¶çš„ç›®å½•
        max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°

    Returns:
        Dict: åŒ…å«å¤„ç†ç»“æœçš„æ±‡æ€»ä¿¡æ¯
    """
    print(f"\n{'=' * 60}")
    print(f"å¼€å§‹æ‰¹é‡å¤„ç†æ¼æ´ç±»å‹å¯¹é½")
    print(f"ç›®å½•: {output_dir}")
    print(f"{'=' * 60}\n")

    # è·å–æ‰€æœ‰ JSON ç»“æœæ–‡ä»¶ (æ’é™¤ summary.json)
    json_files = []
    for file in os.listdir(output_dir):
        if file.endswith('_result.json') and file != 'summary.json':
            json_files.append(os.path.join(output_dir, file))

    if not json_files:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç»“æœ JSON æ–‡ä»¶")
        return {
            "total_files": 0,
            "processed_files": 0,
            "total_vulnerabilities": 0,
            "aligned_vulnerabilities": 0,
            "failed_vulnerabilities": 0
        }

    print(f"æ‰¾åˆ° {len(json_files)} ä¸ª JSON æ–‡ä»¶\n")

    # å¹¶è¡Œå¤„ç†æ–‡ä»¶
    alignment_results = {}
    total_vulnerabilities = 0
    total_aligned = 0
    total_failed = 0

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_file = {
            executor.submit(process_single_vulnerability_alignment, file): file
            for file in json_files
        }

        # è·å–ç»“æœ
        for future in as_completed(future_to_file):
            file_path, result = future.result()
            alignment_results[file_path] = result

            # ç´¯è®¡ç»Ÿè®¡
            total_vulnerabilities += result["total_count"]
            total_aligned += result["success_count"]
            total_failed += len(result["failed_vulnerabilities"])

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    summary = {
        "total_files": len(json_files),
        "processed_files": len(alignment_results),
        "successful_files": sum(1 for r in alignment_results.values() if r["status"] == "success"),
        "failed_files": sum(1 for r in alignment_results.values() if r["status"] == "error"),
        "total_vulnerabilities": total_vulnerabilities,
        "aligned_vulnerabilities": total_aligned,
        "failed_vulnerabilities": total_failed,
        "alignment_rate": f"{(total_aligned / total_vulnerabilities * 100):.2f}%" if total_vulnerabilities > 0 else "0%",
        "details": {}
    }

    # æ·»åŠ æ¯ä¸ªæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯
    for file_path, result in alignment_results.items():
        file_name = os.path.basename(file_path)
        summary["details"][file_name] = {
            "status": result["status"],
            "total": result["total_count"],
            "aligned": result["success_count"],
            "failed": len(result["failed_vulnerabilities"]),
            "error_message": result.get("error_message")
        }

    # ä¿å­˜æ±‡æ€»ç»“æœ
    alignment_summary_path = os.path.join(output_dir, "alignment_summary.json")
    try:
        with open(alignment_summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ å¯¹é½æ±‡æ€»å·²ä¿å­˜è‡³: {alignment_summary_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¯¹é½æ±‡æ€»å¤±è´¥: {e}")

    # ä¿å­˜è¯¦ç»†çš„å¯¹é½ç»“æœ
    detailed_results_path = os.path.join(output_dir, "alignment_detailed_results.json")
    try:
        with open(detailed_results_path, 'w', encoding='utf-8') as f:
            json.dump(alignment_results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è¯¦ç»†å¯¹é½ç»“æœå·²ä¿å­˜è‡³: {detailed_results_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜è¯¦ç»†å¯¹é½ç»“æœå¤±è´¥: {e}")

    # æ‰“å°æ±‡æ€»ä¿¡æ¯
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š æ¼æ´ç±»å‹å¯¹é½å®Œæˆ")
    print(f"{'=' * 60}")
    print(f"å¤„ç†æ–‡ä»¶: {summary['processed_files']}/{summary['total_files']}")
    print(f"æ€»æ¼æ´æ•°: {summary['total_vulnerabilities']}")
    print(f"å¯¹é½æˆåŠŸ: {summary['aligned_vulnerabilities']} ({summary['alignment_rate']})")
    print(f"å¯¹é½å¤±è´¥: {summary['failed_vulnerabilities']}")
    print(f"{'=' * 60}\n")

    return summary

#ä½¿ç”¨ç¤ºä¾‹

# ... (ä»£ç ä¸æ‚¨æä¾›çš„å®Œå…¨ä¸€è‡´) ...
INPUT_DIRECTORY = "./audit_reports"  # å­˜æ”¾å®¡è®¡æŠ¥å‘Šçš„ç›®å½•
OUTPUT_DIRECTORY = "./extracted_knowledge"  # è¾“å‡ºç»“æœçš„ç›®å½•
#
#
#     # æ‰§è¡Œæ‰¹é‡å¤„ç†
#     results = batch_process_audit_reports(
#         input_dir=INPUT_DIRECTORY,
#         output_dir=OUTPUT_DIRECTORY,
#         max_workers=8  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
#     )
batch_process_vulnerability_alignment(OUTPUT_DIRECTORY)